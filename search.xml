<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>GPU高性能编程（三）CUDA-C的入门</title>
      <link href="/gpu-gao-xing-neng-bian-cheng-san-cuda-c-de-ru-men/"/>
      <url>/gpu-gao-xing-neng-bian-cheng-san-cuda-c-de-ru-men/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本章将编写第一段CUDA C的代码，以及了解主机（Host）和设备（Device）之间编写代码的区别，并且查询CUDA的设备信息</p></blockquote><hr><h2 id="Hello-World"><a href="#Hello-World" class="headerlink" title="Hello World"></a>Hello World</h2><p>首先给出一个hello world的示例，这是编写在主机上的hello world程序。</p><pre class=" language-c"><code class="language-c"><span class="token macro property">#<span class="token directive keyword">include</span> <span class="token string">&lt;iostream></span></span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"Hello World!!"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//或者使用std::cout&lt;&lt;"Hello World";</span>    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">}</span></code></pre><p>CPU以及系统的内存称之为<strong>主机</strong>(Host)，GPU及其内存称为<strong>设备</strong>(Device) 。<br>接下来编写在GPU上执行的代码，也就是在设备上执行代码。在GPU设备上执行的函数通常称为<strong>核函数</strong>(Kernel) 。</p><pre class=" language-c"><code class="language-c"><span class="token macro property">#<span class="token directive keyword">include</span> <span class="token string">&lt;iostream></span></span>__global__ <span class="token keyword">void</span> <span class="token function">kernel</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token punctuation">)</span><span class="token punctuation">{</span>  kernel<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token operator">>></span><span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  std<span class="token punctuation">:</span><span class="token punctuation">:</span>cout<span class="token operator">&lt;&lt;</span><span class="token string">"Hello World!"</span><span class="token punctuation">;</span>    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">}</span></code></pre><p>其中：</p><ul><li>使用修饰符<strong>__global__</strong>，这个将告诉编译器，函数应该在设备上运行。函数kernel()将被交给编译设备代码的编译器，main()函数将被交给主机编译器</li><li>采用修饰字符 <strong>&lt;&lt;&lt;1,1&gt;&gt;&gt;</strong>,第一个参数表示设备在执行核函数时使用并行线程块的数量，第二个参数表示每个线程块启动多少线程。</li></ul><hr><h2 id="传递参数"><a href="#传递参数" class="headerlink" title="传递参数"></a>传递参数</h2><p>对之前的hello world程序进行修改，使核函数不是空函数。</p><pre class=" language-c"><code class="language-c"><span class="token macro property">#<span class="token directive keyword">include</span> <span class="token string">&lt;iostream></span></span>__global__ <span class="token keyword">void</span> <span class="token function">add</span><span class="token punctuation">(</span><span class="token keyword">int</span> a<span class="token punctuation">,</span><span class="token keyword">int</span> b<span class="token punctuation">,</span><span class="token keyword">int</span> <span class="token operator">*</span>c<span class="token punctuation">)</span><span class="token punctuation">{</span>  <span class="token operator">*</span>c<span class="token operator">=</span>a<span class="token operator">+</span>b<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token punctuation">)</span><span class="token punctuation">{</span>  <span class="token keyword">int</span> c<span class="token punctuation">;</span>  <span class="token keyword">int</span> <span class="token operator">*</span>dev_c<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//在设备上的变量，会单独开辟内存</span>  <span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token operator">*</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>dev_c<span class="token punctuation">,</span><span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//在设备上开辟内存</span>  add<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token operator">>></span><span class="token operator">></span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span>dev_c<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token function">cudaMemcpy</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>c<span class="token punctuation">,</span>dev_c<span class="token punctuation">,</span><span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">)</span><span class="token punctuation">,</span>cudaMemcpyDeviceToHost<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//将设备上的dev_c传到主机c上，                                                                                                    cudaMemcpyDeviceToHost关键字表示从设备到主机。</span>  std<span class="token punctuation">:</span><span class="token punctuation">:</span>cout<span class="token operator">&lt;&lt;</span><span class="token string">"2+7="</span><span class="token operator">&lt;&lt;</span>c<span class="token punctuation">;</span>  <span class="token function">cudaFree</span><span class="token punctuation">(</span>dev_c<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//记住一定要释放内存</span><span class="token punctuation">}</span></code></pre><p>关于cudaMalloc，cudaFree，cudaMemcpy的用法都写在注释中。</p><hr><h2 id="查询设备"><a href="#查询设备" class="headerlink" title="查询设备"></a>查询设备</h2><p>cuda中有专门的函数对设备上的信息进行查询，cudaGetDeviceProperties函数会返回一个cuda的设备信息结构cudaDeviceProp。</p><pre class=" language-c"><code class="language-c"><span class="token keyword">struct</span> cudaDeviceProp<span class="token punctuation">{</span>  <span class="token keyword">char</span> name<span class="token punctuation">[</span><span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">;</span>                  <span class="token comment" spellcheck="true">//设备的ASCLL字符串，名字</span>  size_t totalGlobalMem<span class="token punctuation">;</span>                <span class="token comment" spellcheck="true">//设备上全局内存的总量，单位为字节</span>  size_t shareMemPerBlock<span class="token punctuation">;</span>            <span class="token comment" spellcheck="true">//在一个线程块（Block）中可使用的最大共享内存，单位为字节</span>  <span class="token keyword">int</span> regsPerBlock<span class="token punctuation">;</span>                            <span class="token comment" spellcheck="true">//每个线程块中可用的32位寄存器数量</span>  <span class="token keyword">int</span> warpSize<span class="token punctuation">;</span>                                    <span class="token comment" spellcheck="true">//在一个线程束（Warp）中包含的线程数量</span>  size_t memPitch<span class="token punctuation">;</span>                            <span class="token comment" spellcheck="true">//在内存复制中最大的修正量（Pitch），单位为字节</span>  <span class="token keyword">int</span> maxThreadsPerBlock<span class="token punctuation">;</span>                <span class="token comment" spellcheck="true">//在一个线程块中可以包含的最大线程数量</span>  <span class="token keyword">int</span> maxThreadsDim<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">;</span>                    <span class="token comment" spellcheck="true">//在多维线程块数组中，每一维可以包含的最大线程数量</span>  <span class="token keyword">int</span> maxGridSize<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">;</span>                        <span class="token comment" spellcheck="true">//在一个线程格（Grid）中，每一维可以包含的线程块数量</span>  size_t totalConstMem<span class="token punctuation">;</span>                    <span class="token comment" spellcheck="true">//常量内存的总量</span>  <span class="token keyword">int</span> major<span class="token punctuation">;</span>                                        <span class="token comment" spellcheck="true">//设备计算功能集的主版本号</span>  <span class="token keyword">int</span> minor<span class="token punctuation">;</span>                                        <span class="token comment" spellcheck="true">//设备计算功能集的次版本号</span>  <span class="token keyword">int</span> clockRate<span class="token punctuation">;</span>                                  size_t textureAlignment<span class="token punctuation">;</span>            <span class="token comment" spellcheck="true">//设备的纹理对齐要求</span>  <span class="token keyword">int</span> deviceOverlap<span class="token punctuation">;</span>                        <span class="token comment" spellcheck="true">//一个bool值，表示设备是否可以同时执行cudaMemory和核函数调用</span>  <span class="token keyword">int</span> multiProcessorCount<span class="token punctuation">;</span>            <span class="token comment" spellcheck="true">//设备上多处理器的数量</span>  <span class="token keyword">int</span> kernelExecTimeoutEnabled<span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//一个bool值，表示核函数是否存在运行时限制</span>  <span class="token keyword">int</span> integrated<span class="token punctuation">;</span>                                <span class="token comment" spellcheck="true">//一个bool值，表示设备是否是一个集成GPU（属于芯片组的一部分）</span>  <span class="token keyword">int</span> canMapHostMemory<span class="token punctuation">;</span>                    <span class="token comment" spellcheck="true">//一个bool值，表示设备是否可以将主机内存映射到CUDA设备地址空间</span>  <span class="token keyword">int</span> computeMode<span class="token punctuation">;</span>                            <span class="token comment" spellcheck="true">//设备的计算模式：默认（Default）、独占（Exclusive）、禁止（Prohibited）</span>  <span class="token keyword">int</span> maxTexture1D<span class="token punctuation">;</span>                            <span class="token comment" spellcheck="true">//一维纹理的最大大小</span>  <span class="token keyword">int</span> maxTexture2D<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">;</span>                    <span class="token comment" spellcheck="true">//二维纹理的最大维数</span>  <span class="token keyword">int</span> maxTexture3D<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">;</span>                    <span class="token comment" spellcheck="true">//三维纹理的最大维数</span>  <span class="token keyword">int</span> maxTexture2DArray<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">;</span>            <span class="token comment" spellcheck="true">//二维纹理数组的最大维数</span>  <span class="token keyword">int</span> concurrentKernels<span class="token punctuation">;</span>                <span class="token comment" spellcheck="true">//一个bool值，表示设备是否支持在同一个上下文中同时执行多个核函数</span><span class="token punctuation">}</span></code></pre><p>简单获取一下设备信息：</p><pre class=" language-c"><code class="language-c"><span class="token macro property">#<span class="token directive keyword">include</span> <span class="token string">&lt;iostream></span></span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token punctuation">)</span><span class="token punctuation">{</span>  cudaDeviceProp prop<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//构建一个结构, 用来获取设备信息</span>  <span class="token keyword">int</span> count<span class="token punctuation">;</span>  <span class="token function">cudaGetDeviceCount</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>count<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//获取设备数量，可能有多块GPU</span>  <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span>i<span class="token operator">&lt;</span>count<span class="token punctuation">;</span>i<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token function">cudaGetDeviceProperties</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>prop<span class="token punctuation">,</span>i<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//获取对应设备上的信息</span>    std<span class="token punctuation">:</span><span class="token punctuation">:</span>cout<span class="token operator">&lt;&lt;</span><span class="token string">"id "</span><span class="token operator">&lt;&lt;</span>i<span class="token operator">&lt;&lt;</span><span class="token string">" name: "</span><span class="token operator">&lt;&lt;</span>prop<span class="token punctuation">.</span>name<span class="token punctuation">;</span>  <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><p>本章到此结束，其实CUDA C很类似于C。可以说是为GPU专门设计的C语言。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> GPU编程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GPU </tag>
            
            <tag> CUDA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GPU高性能编程（二）CUDA C的开发环境</title>
      <link href="/gpu-gao-xing-neng-bian-cheng-er-cuda-c-de-kai-fa-huan-jing/"/>
      <url>/gpu-gao-xing-neng-bian-cheng-er-cuda-c-de-kai-fa-huan-jing/</url>
      
        <content type="html"><![CDATA[<blockquote><p>这章主要介绍进行CUDA编程所需要的软件和开发环境，包括</p><ul><li>支持CUDA的图形处理器</li><li>NVIDIA设备驱动器</li><li>CUDA开发工具箱</li><li>标准C编译器</li></ul><p>想要编写CUDA C程序，则需要上面所列出的工具</p></blockquote><hr><h2 id="支持CUDA的图形处理器"><a href="#支持CUDA的图形处理器" class="headerlink" title="支持CUDA的图形处理器"></a>支持CUDA的图形处理器</h2><p>我们所说的<strong>GPU</strong>（Graphics Processing Unit），就是图形处理器。NVIDIA公司一直在不断推出基于CUDA架构的新GPU，完整的信息可以参考<a href="https://developer.nvidia.com/cuda-gpus" target="_blank" rel="noopener">NVIDIA的网址</a>上支持CUDA的GPU给出的信息。具体列表就不列出了。</p><hr><h2 id="NVIDIA设备驱动程序"><a href="#NVIDIA设备驱动程序" class="headerlink" title="NVIDIA设备驱动程序"></a>NVIDIA设备驱动程序</h2><p>NVIDIA提供了一些系统软件来支持应用程序和支持CUDA的硬件之间的通信，一般正确安装了NVIDIA的GPU，这些系统软件应该也已经安装好了，可以访问<a href="https://developer.nvidia.com/drive" target="_blank" rel="noopener">网址</a>，根据所选平台的安装指令去安装最新的NVIDIA设备驱动程序。</p><hr><h2 id="CUDA开发工具箱"><a href="#CUDA开发工具箱" class="headerlink" title="CUDA开发工具箱"></a>CUDA开发工具箱</h2><p>有了支持CUDA的GPU以及相应的NVIDIA设备驱动程序后，就可以运行编译好的CUDA C代码了，意味着可以下载CUDA编写的应用程序，并且在GPU上执行，然而想要用CUDA C为GPU开发代码，则需要相关的开发工具箱，也就是CUDA C的编译器。CUDA C的程序将在两个不同的处理器上执行计算，因此有两个编译器，一个编译器编译GPU设备代码，一个编译器编译CPU主机代码。GPU的编译器在<a href="https://developer.nvidia.com/cuda-toolkit" target="_blank" rel="noopener">NVIDIA网址</a>上可以下载，下载CUDA工具箱，如图。<br><img src="../img/CUDA%E4%B8%8B%E8%BD%BD%E7%95%8C%E9%9D%A2.png" alt="CUDA下载界面"></p><hr><h2 id="标准的C编译器"><a href="#标准的C编译器" class="headerlink" title="标准的C编译器"></a>标准的C编译器</h2><p>前面说到需要两个编译器，一个编译GPU，一个编译CPU，编译GPU的下载好了，只剩一个CPU编译器。Windows和Linux以及Mac OS上都有相应的C编译器。</p><ol><li>Windows平台上一般选择Visual Studio，可以去相应平台下载</li><li>Linux大多数发行版本都自带有一个GNU C编译器（gcc），下载相应版本即可</li><li>Mac OS X上则需要确保版本不低于10.5.7，可以通过苹果的Xcode来安装gcc</li></ol><hr><p>按照本章的步骤一一实现，就准备好了额CUDA C的开发环境，可以开始进行GPU编程了！</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> GPU编程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GPU </tag>
            
            <tag> CUDA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GPU高性能编程（一）GPU和CUDA介绍</title>
      <link href="/gpu-gao-xing-neng-bian-cheng-yi-gpu-jie-shao/"/>
      <url>/gpu-gao-xing-neng-bian-cheng-yi-gpu-jie-shao/</url>
      
        <content type="html"><![CDATA[<blockquote><p>CUDA（Compute Unified Device Architecture，计算统一设备架构），在图像领域的同学多多少少都会接触到，其相关的硬件是GPU（Graphics Processing Unit，图形处理器），下面将从以下3个方面介绍：</p></blockquote><hr><h2 id="GPU架构特点"><a href="#GPU架构特点" class="headerlink" title="GPU架构特点"></a>GPU架构特点</h2><p>高性能计算的关键利用多核处理器进行并行计算。计算分为<strong>串行计算</strong>和<strong>并行计算</strong>。但是串行计算的缺点非常明显，如果我们拥有多核处理器，多个任务之间不需要相互依赖，那么使用串形计算速度就很慢，可以把一些独立的模块分配到不同的处理器上进行同时计算（并行），最后再将这些结果进行整合，完成一次任务计算。<br>GPU和CPU的不同硬件特点决定了他们的应用场景，CPU是计算机的运算和控制的核心，GPU主要用作图形图像处理。</p><hr><ul><li>CPU需要很强的通用性来处理各种不同的数据类型，比如整型、浮点数等，同时它又必须擅长处理逻辑判断所导致的大量分支跳转和中断处理，擅长流程控制和逻辑处理，不规则数据结构，不可预测存储结构，单线程程序，分支密集型算法。</li><li>GPU面对的则是类型高度统一的、相互无依赖的大规模数据和不需要被打断的纯净的计算环境，GPU有非常多核心，擅长数据并行计算，规则数据结构，可预测存储模式。</li></ul><hr><p><img src="../img/cpu.png" alt="cpu"><br><img src="../img/gpu.jpg" alt="gpu"></p><p>现在的计算机体系架构中，要完成CUDA并行计算，单靠GPU一人之力是不能完成计算任务的，必须借助CPU来协同配合完成一次高性能的并行计算任务。<br>并行部分在GPU上运行，串行部分在CPU运行，这就是异构计算。异构计算的意思就是不同体系结构的处理器相互协作完成计算任务。CPU负责总体的程序流程，而GPU负责具体的计算任务，当GPU各个线程完成计算任务后，就将GPU那边计算得到的结果拷贝到CPU端，完成一次计算任务。<br>应用程序利用GPU实现加速的总体分工就是：密集计算代码（约占5%的代码量）由GPU负责完成，剩余串行代码由CPU负责执行。</p><hr><h2 id="CUDA线程模型"><a href="#CUDA线程模型" class="headerlink" title="CUDA线程模型"></a>CUDA线程模型</h2><p>线程是程序执行的最基本单元，CUDA的并行计算就是通过成千上万个线程的并行执行来实现的。<br><img src="../img/cuda%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B.jpg" alt="cuda线程模型"></p><p>CUDA的线程模型包括：</p><ul><li>Thread：线程，并行的基本单位</li><li>Thread Block：线程块，互相合作的线程组，它的特点是：<ul><li>允许彼此同步</li><li>可以通过共享内存快速交换数据</li><li>以1维、2维或3维组织</li></ul></li><li>Grid：一组线程块，它的特点是：<ul><li>以1维、2维组织</li><li>共享全局内存</li></ul></li></ul><p>Kernel是在GPU上执行的核心程序，kernel函数是运行在某个Grid上的。理解kernel，必须要对kernel的线程层次结构有一个清晰的认识。</p><ul><li>首先GPU上很多并行化的轻量级线程。kernel在device上执行时实际上是启动很多线程，一个kernel所启动的所有线程称为一个网格（grid），同一个网格上的线程共享相同的全局内存空间，grid是线程结构的第一层次。</li><li>网格又可以分为很多线程块（block），一个线程块里面包含很多线程，这是第二个层次。</li><li>kernel调用时也必须通过执行配置&lt;&lt;&lt;grid, block&gt;&gt;&gt;来指定kernel所使用的网格维度和线程块维度。</li></ul><hr><p>这里解释一下SP和SM专业名词。</p><ul><li>SP（streaming processor,流处理器）：基本的处理单元，也称为CUDA core。最后具体的指令和任务都是在SP上处理的。GPU进行并行计算，也就是很多个SP同时做处理。</li><li>SM（streaming multiprocessor）：多个SP加上其他的一些资源组成，也叫GPU大核，其他资源如：warp scheduler，register，shared memory等。SM可以看做GPU的心脏（对比CPU核心），register和shared memory是SM的稀缺资源。CUDA将这些资源分配给所有驻留在SM中的threads。因此，这些有限的资源就使每个SM中active warps有非常严格的限制，也就限制了并行能力。</li><li>warp：GPU执行程序时的调度单位，目前cuda的warp的大小为32，同在一个warp的线程，以不同数据资源执行相同的指令.warp通常被硬件的SIMD（single instruction multiple data，单指令多数据流）模块执行.</li></ul><p>SP是线程执行的硬件单位，SM中包含多个SP，一个GPU可以有多个SM，最终一个GPU可能包含有上千个SP。这么多核心“同时运行”，这个引号只是想表明实际上，软件逻辑上是所有SP是并行的，但是物理上并不是所有SP都能同时执行计算（比如我们只有8个SM却有1024个线程块需要调度处理），因为有些会处于挂起，就绪等其他状态，这有关GPU的线程调度。<br>&nbsp;&nbsp;从硬件角度和软件角度解释CUDA的线程模型：<br><img src="../img/cuda%E8%BD%AF%E7%A1%AC%E4%BB%B6%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B.jpg" alt="cuda软硬件线程模型"></p><p>具体来说：</p><ul><li>每个线程由每个线程处理器（SP）执行</li><li>线程块由多核处理器（SM）执行</li><li>一个kernel由一个grid来执行，一个kernel一次只能在一个GPU上执行</li></ul><p>对应关系是：<br>一个SP可以执行一个thread，但是实际上并不是所有的thread能够在同一时刻执行。Nvidia把32个threads组成一个warp，<strong>warp是thread调度和运行的基本单元</strong>。warp中所有threads并行的执行相同的指令。一个warp需要占用一个SM运行，多个warps需要轮流进入SM。由SM的硬件warp scheduler负责调度。目前每个warp包含32个threads。所以，一个GPU上resident thread最多只有 SM*warp个。</p><p>每个sm中 thread slots /block slots/ register 都是有限的<br><img src="../img/%E8%B5%84%E6%BA%90%E6%A8%A1%E5%9E%8B.jpg" alt="资源模型"></p><hr><p>sm结构：sm,gpc(处理核集群),sp,share memory,register<br><img src="../img/sm%E7%BB%93%E6%9E%84.jpg" alt="sm结构"></p><p>这是一个sm,含有4个gpc,一块share memory.每个gpc里面含有1个Warp Scheduler,16384x32bit的register资源.该sm共有128个cuda core(sp).</p><ul><li>同一个grid的不同block会被发射到不同的sm上执行.</li><li>同一个sm上会有来自不同kernel的block执行.</li><li>每个thread的局部变量存储在register中.</li><li>register和share memory的数量限制该sm上可以同时存在的block数.</li><li>block里面的thread会按照warp划分,分组到cuda core中执行,这里gpc中有32个core正好warp也是32,这样一个warp到一个gpc中的32个core中执行.</li></ul><hr><h2 id="CUDA内存模型"><a href="#CUDA内存模型" class="headerlink" title="CUDA内存模型"></a>CUDA内存模型</h2><p>CUDA中的内存模型分为以下几个层次：</p><ul><li>每个线程都用自己的registers（寄存器）</li><li>每个线程都有自己的local memory（局部内存）</li><li>每个线程块内都有自己的shared memory（共享内存），所有线程块内的所有线程共享这段内存资源</li><li>每个grid都有自己的global memory（全局内存），不同线程块的线程都可使用</li><li>每个grid都有自己的constant memory（常量内存）和texture memory（纹理内存），），不同线程块的线程都可使用</li></ul><p>线程访问这几类存储器的速度是register &gt; local memory &gt;shared memory &gt; global memory<br><img src="../img/%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B.jpg" alt="内存模型"></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> GPU编程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GPU </tag>
            
            <tag> CUDA </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
